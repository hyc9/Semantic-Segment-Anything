{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like shi-labs/oneformer_ade20k_swin_large is not the path to a directory containing a file named preprocessor_config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLocalEntryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/ssa/lib/python3.8/site-packages/transformers/utils/hub.py:409\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ssa/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:120\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ssa/lib/python3.8/site-packages/huggingface_hub/file_download.py:1259\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1258\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1259\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[1;32m   1260\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection error, and we cannot find the requested files in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1261\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the disk cache. Please try again or make sure your Internet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1262\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m connection is on.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1263\u001b[0m         )\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;66;03m# From now on, etag and commit_hash are not None.\u001b[39;00m\n",
      "\u001b[0;31mLocalEntryNotFoundError\u001b[0m: Connection error, and we cannot find the requested files in the disk cache. Please try again or make sure your Internet connection is on.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#url = \"https://huggingface.co/datasets/shi-labs/oneformer_demo/blob/main/ade20k.jpeg\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#image = Image.open(requests.get(url, stream=True).raw)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Loading a single model for all three tasks\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m processor \u001b[38;5;241m=\u001b[39m \u001b[43mOneFormerProcessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshi-labs/oneformer_ade20k_swin_large\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m OneFormerForUniversalSegmentation\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshi-labs/oneformer_ade20k_swin_large\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Semantic Segmentation\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ssa/lib/python3.8/site-packages/transformers/processing_utils.py:184\u001b[0m, in \u001b[0;36mProcessorMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    155\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    Instantiate a processor associated with a pretrained model.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m            [`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`].\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_arguments_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ssa/lib/python3.8/site-packages/transformers/processing_utils.py:228\u001b[0m, in \u001b[0;36mProcessorMixin._get_arguments_from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m         attribute_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(transformers_module, class_name)\n\u001b[0;32m--> 228\u001b[0m     args\u001b[38;5;241m.\u001b[39mappend(\u001b[43mattribute_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ssa/lib/python3.8/site-packages/transformers/image_processing_utils.py:164\u001b[0m, in \u001b[0;36mImageProcessingMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pretrained_model_name_or_path: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     84\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    Instantiate a type of [`~image_processing_utils.ImageProcessingMixin`] from an image processor.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    assert unused_kwargs == {\"foo\": False}\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    ```\"\"\"\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m     image_processor_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_processor_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_dict(image_processor_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ssa/lib/python3.8/site-packages/transformers/image_processing_utils.py:268\u001b[0m, in \u001b[0;36mImageProcessingMixin.get_image_processor_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m image_processor_file \u001b[38;5;241m=\u001b[39m IMAGE_PROCESSOR_NAME\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     resolved_image_processor_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_processor_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ssa/lib/python3.8/site-packages/transformers/utils/hub.py:443\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_missing_entries \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_connection_errors:\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt connect to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to load this file, couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find it in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m cached files and it looks like \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not the path to a directory containing a file named\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCheckout your internet connection or see how to run the library in offline mode at\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m     )\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_missing_entries:\n",
      "\u001b[0;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like shi-labs/oneformer_ade20k_swin_large is not the path to a directory containing a file named preprocessor_config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "from transformers import OneFormerProcessor, OneFormerForUniversalSegmentation\n",
    "from PIL import Image\n",
    "import requests\n",
    "#url = \"https://huggingface.co/datasets/shi-labs/oneformer_demo/blob/main/ade20k.jpeg\"\n",
    "#image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# Loading a single model for all three tasks\n",
    "processor = OneFormerProcessor.from_pretrained(\"shi-labs/oneformer_ade20k_swin_large\")\n",
    "model = OneFormerForUniversalSegmentation.from_pretrained(\"shi-labs/oneformer_ade20k_swin_large\")\n",
    "\n",
    "# Semantic Segmentation\n",
    "semantic_inputs = processor(images=image, task_inputs=[\"semantic\"], return_tensors=\"pt\")\n",
    "semantic_outputs = model(**semantic_inputs)\n",
    "# pass through image_processor for postprocessing\n",
    "predicted_semantic_map = processor.post_process_semantic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n",
    "\n",
    "# Instance Segmentation\n",
    "instance_inputs = processor(images=image, task_inputs=[\"instance\"], return_tensors=\"pt\")\n",
    "instance_outputs = model(**instance_inputs)\n",
    "# pass through image_processor for postprocessing\n",
    "predicted_instance_map = processor.post_process_instance_segmentation(outputs, target_sizes=[image.size[::-1]])[0][\"segmentation\"]\n",
    "\n",
    "# Panoptic Segmentation\n",
    "panoptic_inputs = processor(images=image, task_inputs=[\"panoptic\"], return_tensors=\"pt\")\n",
    "panoptic_outputs = model(**panoptic_inputs)\n",
    "# pass through image_processor for postprocessing\n",
    "predicted_semantic_map = processor.post_process_panoptic_segmentation(outputs, target_sizes=[image.size[::-1]])[0][\"segmentation\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是完整补全后的代码，包括：\n",
    "# 1. 封装后的 `semantic_infer_one_image()` 函数\n",
    "# 2. 支持从 WebDataset 中读取图像，生成语义 mask，并存回新 tar 的主程序流程\n",
    "# 3. 多卡分布式运行支持\n",
    "\n",
    "import os\n",
    "import io\n",
    "import tarfile\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "from datasets import load_dataset\n",
    "from torchvision.transforms import Resize\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import torch.nn.functional as F\n",
    "from transformers import (\n",
    "    CLIPProcessor, CLIPModel,\n",
    "    AutoProcessor, CLIPSegForImageSegmentation,\n",
    "    OneFormerProcessor, OneFormerForUniversalSegmentation,\n",
    "    BlipProcessor, BlipForConditionalGeneration\n",
    ")\n",
    "from clip import clip_classification\n",
    "from clipseg import clipseg_segmentation\n",
    "from oneformer import oneformer_coco_segmentation, oneformer_ade20k_segmentation\n",
    "from blip import open_vocabulary_classification_blip\n",
    "from configs.ade20k_id2label import CONFIG as CONFIG_ADE20K_ID2LABEL\n",
    "from configs.coco_id2label import CONFIG as CONFIG_COCO_ID2LABEL\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "# 参数配置\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '12355'\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "\n",
    "input_dir = '/mnt/33t/cy/blip3o_dataset'\n",
    "output_dir = '/mnt/33t/cy/mask_dataset'\n",
    "base_dir = '/mnt/33t/cy/mllm_models/semantic_sam'\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--world_size', type=int, default=1)\n",
    "    parser.add_argument('--save_img', action='store_true')\n",
    "    parser.add_argument('--ckpt_path', type=str, required=True)\n",
    "    return parser.parse_args()\n",
    "\n",
    "# ====================== 语义推理函数 ======================\n",
    "def semantic_infer_one_image(img: Image.Image, processors, models, rank) -> np.ndarray:\n",
    "    \"\"\"对一张图像执行语义标注，返回 shape=(256,) 的单通道 numpy array，值为 0~num_class\"\"\"\n",
    "    from mmcv import imcrop\n",
    "    import pycocotools.mask as maskUtils\n",
    "\n",
    "    img = np.array(img.convert(\"RGB\"))\n",
    "    anns = {'annotations': processors['sam_generator'].generate(img)}\n",
    "    class_ids_from_oneformer_coco = oneformer_coco_segmentation(Image.fromarray(img),\n",
    "                                                                 processors['oneformer_coco'], models['oneformer_coco'], rank)\n",
    "    class_ids_from_oneformer_ade20k = oneformer_ade20k_segmentation(Image.fromarray(img),\n",
    "                                                                     processors['oneformer_ade20k'], models['oneformer_ade20k'], rank)\n",
    "    semantic_mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "    for ann in anns['annotations']:\n",
    "        valid_mask = torch.tensor(maskUtils.decode(ann['segmentation'])).bool()\n",
    "        coco_ids = class_ids_from_oneformer_coco[valid_mask]\n",
    "        ade_ids = class_ids_from_oneformer_ade20k[valid_mask]\n",
    "        coco_labels = [CONFIG_COCO_ID2LABEL['refined_id2label'].get(str(i.item()), '') for i in torch.bincount(coco_ids).topk(1).indices]\n",
    "        ade_labels = [CONFIG_ADE20K_ID2LABEL['id2label'].get(str(i.item()), '') for i in torch.bincount(ade_ids).topk(1).indices]\n",
    "        labels = list(set(coco_labels + ade_labels))\n",
    "\n",
    "        x0, y0, w, h = ann['bbox']\n",
    "        patch = imcrop(img, np.array([x0, y0, x0+w, y0+h]), scale=1.5)\n",
    "        open_vocab_labels = open_vocabulary_classification_blip(patch, processors['blip'], models['blip'], rank)\n",
    "        candidate_labels = list(set(labels + open_vocab_labels))\n",
    "        top_labels = clip_classification(patch, candidate_labels, min(3, len(candidate_labels)),\n",
    "                                         processors['clip'], models['clip'], rank)\n",
    "        seg = clipseg_segmentation(patch, top_labels, processors['clipseg'], models['clipseg'], rank).argmax(0)\n",
    "\n",
    "        ann_mask = torch.tensor(maskUtils.decode(ann['segmentation']))\n",
    "        if ann_mask.shape != seg.shape:\n",
    "            ann_mask = F.interpolate(ann_mask.unsqueeze(0).unsqueeze(0).float(), size=seg.shape, mode='nearest').squeeze(0).squeeze(0).bool()\n",
    "        seg = seg.cpu().numpy()\n",
    "        class_name = top_labels[torch.bincount(torch.tensor(seg[ann_mask.numpy()].flatten())).topk(1).indices.item()]\n",
    "        class_id = processors['label2index'].setdefault(class_name.lower().strip(\" a the\"), len(processors['label2index']))\n",
    "        semantic_mask[ann_mask.numpy()] = class_id\n",
    "\n",
    "    h, w = semantic_mask.shape\n",
    "    scale = (256 / (h * w)) ** 0.5\n",
    "    new_h, new_w = max(1, int(h * scale)), max(1, int(w * scale))\n",
    "    mask_img = Image.fromarray(semantic_mask).resize((new_w, new_h), resample=Image.NEAREST)\n",
    "    mask_arr = np.array(mask_img).astype(np.uint8).flatten()\n",
    "    return mask_arr  # shape = (256,) numpy array\n",
    "\n",
    "# ====================== 主函数 ======================\n",
    "def main(rank, args):\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=args.world_size)\n",
    "    device = torch.device(f\"cuda:{rank}\")\n",
    "\n",
    "    # 模型与处理器初始化\n",
    "    processors = {\n",
    "        'clip': CLIPProcessor.from_pretrained(f\"{base_dir}/clip-vit-large-patch14\"),\n",
    "        'clipseg': AutoProcessor.from_pretrained(f\"{base_dir}/clipseg-rd64-refined\"),\n",
    "        'oneformer_ade20k': OneFormerProcessor.from_pretrained(\"shi-labs/oneformer_ade20k_swin_large\"),\n",
    "        'oneformer_coco': OneFormerProcessor.from_pretrained(\"shi-labs/oneformer_coco_swin_large\"),\n",
    "        'blip': BlipProcessor.from_pretrained(f\"{base_dir}/blip-image-captioning-large\"),\n",
    "        'label2index': {}\n",
    "    }\n",
    "    processors['clipseg'].image_processor.do_resize = False\n",
    "\n",
    "    models = {\n",
    "        'clip': CLIPModel.from_pretrained(f\"{base_dir}/clip-vit-large-patch14\").to(device),\n",
    "        'clipseg': CLIPSegForImageSegmentation.from_pretrained(f\"{base_dir}/clipseg-rd64-refined\").to(device),\n",
    "        'oneformer_ade20k': OneFormerForUniversalSegmentation.from_pretrained(\"shi-labs/oneformer_ade20k_swin_large\").to(device),\n",
    "        'oneformer_coco': OneFormerForUniversalSegmentation.from_pretrained(\"shi-labs/oneformer_coco_swin_large\").to(device),\n",
    "        'blip': BlipForConditionalGeneration.from_pretrained(f\"{base_dir}/blip-image-captioning-large\").to(device),\n",
    "    }\n",
    "\n",
    "    sam = sam_model_registry[\"vit_h\"](checkpoint=args.ckpt_path).to(device)\n",
    "    processors['sam_generator'] = SamAutomaticMaskGenerator(model=sam, points_per_side=32,\n",
    "        pred_iou_thresh=0.86, stability_score_thresh=0.92, crop_n_layers=0,\n",
    "        crop_n_points_downscale_factor=2, min_mask_region_area=100, output_mode='coco_rle')\n",
    "\n",
    "    # 读取当前进程对应的数据\n",
    "    tar_files = sorted([os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.tar')])\n",
    "    local_files = tar_files[rank::args.world_size]\n",
    "    for tar_path in local_files:\n",
    "        dataset = load_dataset(\"webdataset\", data_files=tar_path, split=\"train\")\n",
    "        tar_name = os.path.splitext(os.path.basename(tar_path))[0]\n",
    "        output_tar_path = os.path.join(output_dir, f\"{tar_name}.tar\")\n",
    "        with tarfile.open(output_tar_path, \"w\") as tar_out:\n",
    "            for item in dataset:\n",
    "                key = item[\"__key__\"]\n",
    "                img: Image.Image = item[\"image\"]\n",
    "                mask_arr = semantic_infer_one_image(img, processors, models, rank)\n",
    "                img_buffer = io.BytesIO()\n",
    "                item[\"image\"].save(img_buffer, format=\"PNG\")\n",
    "                mask_buffer = io.BytesIO(mask_arr.astype(np.uint8).tobytes())\n",
    "\n",
    "                for name, buf in [(\"image.png\", img_buffer), (\"mask.pgm\", mask_buffer)]:\n",
    "                    info = tarfile.TarInfo(f\"{key}/{name}\")\n",
    "                    info.size = buf.getbuffer().nbytes\n",
    "                    buf.seek(0)\n",
    "                    tar_out.addfile(info, buf)\n",
    "        if rank == 0:\n",
    "            print(f\"[rank {rank}] Saved: {output_tar_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    if args.world_size > 1:\n",
    "        mp.spawn(main, args=(args,), nprocs=args.world_size, join=True)\n",
    "    else:\n",
    "        main(0, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65535"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**16 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img_arr = np.random.randint(0, 2^16-1, (64, 64))\n",
    "img = Image.fromarray(img_arr, mode='I;16')\n",
    "img.save('test.png')\n",
    "img.save('test.tiff')\n",
    "np.save('test', img_arr)\n",
    "\n",
    "img_recover_npy = np.load(\"test.npy\")\n",
    "img_recover_tiff = Image.open('test.tiff')\n",
    "img_recover_png = Image.open('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'npy_time': 0.00036334991455078125,\n",
       " 'npy_error': 0,\n",
       " 'tiff_time': 0.0006701946258544922,\n",
       " 'tiff_error': 0,\n",
       " 'png_time': 0.0002529621124267578,\n",
       " 'png_error': 0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Create a synthetic 16-bit image\n",
    "img_arr = np.random.randint(0, 2**16 - 1, (16, 25), dtype=np.uint16)\n",
    "img = Image.fromarray(img_arr, mode='I;16')\n",
    "\n",
    "# Save in different formats\n",
    "img.save('/mnt/data/test.png')\n",
    "img.save('/mnt/data/test.tiff')\n",
    "#img.save('/mnt/data/test.mask')\n",
    "np.save('/mnt/data/test.npy', img_arr)\n",
    "\n",
    "# Load and measure time & error\n",
    "results = {}\n",
    "\n",
    "# NPY\n",
    "start = time.time()\n",
    "img_recover_npy = np.load('/mnt/data/test.npy')\n",
    "results['npy_time'] = time.time() - start\n",
    "results['npy_error'] = np.abs(img_arr.astype(np.int16) - img_recover_npy.astype(np.int16)).max()\n",
    "\n",
    "# TIFF\n",
    "start = time.time()\n",
    "img_recover_tiff = Image.open('/mnt/data/test.tiff')\n",
    "img_recover_tiff = np.array(img_recover_tiff)\n",
    "results['tiff_time'] = time.time() - start\n",
    "results['tiff_error'] = np.abs(img_arr.astype(np.int16) - img_recover_tiff.astype(np.int16)).max()\n",
    "\n",
    "# PNG\n",
    "start = time.time()\n",
    "img_recover_png = Image.open('/mnt/data/test.png')\n",
    "img_recover_png = np.array(img_recover_png)\n",
    "results['png_time'] = time.time() - start\n",
    "results['png_error'] = np.abs(img_arr.astype(np.int16) - img_recover_png.astype(np.int16)).max()\n",
    "\n",
    "results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_arr == img_recover_tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
